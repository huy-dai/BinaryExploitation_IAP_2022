# Binary Exploitation IAP Activity

These are my notes for the challenges released as part of the class.

## Day 1

### babyrev0

I opened up the file in Ghidra. Inspecting the `entry` class I enter the first parameter in the `_libc_start_main` function call (as suggested in class). Reading the decompiled result I could see that it is simply taking our input string, adding 0x1 to each of the characters, and checking the result against `NJU|e2bbf5d4e7c743db8dfdcd7d52gb75b5~` to see if we got the flag or not. 

Reversing this process in Python yields:

~~~py
input = 'NJU|e2bbf5d4e7c743db8dfdcd7d52gb75b5~'

out = ''

for char in input:
    out += chr(ord(char) - 1)

print(out)
~~~

Flag: MIT{d1aae4c3d6b632ca7cecbc6c41fa64a4}


### babyrev1

This challenge followed a similar process as the first challenge except this time the input has each character XOR-ed with 0x50 and then overall string is checked against the stored expected ciphertext.

To reverse that process, do:

~~~py
input = '1d19042b36346335636631606333313336336769656767346936676068673236346934612d'

split = [int(input[i:i+2],16) for i in range(0, len(input), 2)]

out = ''
for entry in split:
    out += chr(entry ^ 0x50)

print(out)
~~~

Flag: MIT{fd3e36a03cacfc79577d9f7087bfd9d1}

### babyrev_finale

For this problem, in the decompiler output we see they are taking our input string, XOR-ing it with another fixed string at index `i & 7`, and checking it against the expected ciphertext. Performing the reverse of that process, we get the flag.

~~~py
ref = 'baadf00d1337babe'
print(len(ref))
input = 'f7e4a4762a06df87dbcb966e26028d8c8998c66b760edb8dd89f953f21528d8fdcc893346e'
print(len(input))

# Function to split string into its hexadecimal parts
split = lambda str : [int(str[i:i+2],16) for i in range(0, len(str), 2)]

in_s = split(input)
ref_s = split(ref)

out = '' 
for i in range(len(in_s)):
    xor = in_s[i] ^ ref_s[i & 7]
    out += chr(xor)
print(out)
print(len(out))
~~~
Note: At first I was making the mistake of copying over the expected ciphertext by hand, which ended up with me making a small typo that took nearly half an hour to figure out. Instead, the easier way to approach this is to convert the typing in Ghidra to identify the expected ciphertext variable as a char array of size 40 and copying the hexadecimal value directly from there.

Flag: MIT{91e9affc5572356fe9a3b2e22e71fec9}

## Day 2

### walzer

Will stepped through the solution during class so I got to see how the binary was broken down in Ghidra, along with relabeling of variables and functions as we worked through the code. Some of the observations / changes were:

* Noting that main() fgets 64 characters from stdin, and uses strcspn to replace the newline character with null character, e.g. to null-terminate the char array

* Renaming char array as `buffer` and strlen variable as `length` for better readibility. 

* In the first custom function call, we see it is performing a weird operation dealing with an extended alphabetic string 'a-zA-z/+'. That, combined with the padding at the end let us know it's performing an encoding. Searching up the special string let us know this is a C implementation of base64 encoding.

* In the second custom function call, we are passing in a char pointer (need to modify function signature to fit that info). It then iterates through the string and, for each character, calls `__ctype_b_loc` on it and check it against the bitmask of 0x400 = 0d1024 to see if result is 1. In effect that is checking if the 11th-bit is set in the result, which is only done when `__ctype_b_loc` determines the character it was given is alphanumeric. (Source: [link](https://stackoverflow.com/questions/37702434/ctype-b-loc-what-is-its-purpose)) Following that it performs a ROT-13 rotation, as evident by the adding + 13 or + -13 depending on the character. Thus we can relabel this function as `rot_13`

* The last custom function involves XOR-ing the string against a given int value, which in this use case is 0d19 and 0d55 (the encryption process is done twice)

Once we were able to identify the encryption steps, we could reverse it as follows:

~~~py
import base64
import codecs

inc = b'\x7e\x64\x50\x53\x7d\x05\x64\x1c\x7c\x4d\x7a\x71\x61\x7e\x54\x54\x7c\x5b\x64\x79\x7a\x64\x64\x67\x7b\x5b\x60\x44\x7a\x65\x65\x41\x7f\x7e\x72\x58\x45\x7e\x0e\x54\x7e\x4d\x7e\x60\x7e\x63\x54\x53\x7c\x06\x4e\x59\x59\x4e\x0e\x7f\x7e\x4d\x7a\x44\x7e\x64\x5c\x52\x7b\x64\x47\x5f\x6e\x43\x0a\x0a'

def xor(str,val):
    out = []
    for byte in str:
        out.append(byte ^ val)
    return bytes(out)

dec = inc
dec = xor(inc,55)
dec = bytes(codecs.encode(str(dec,'ascii'),'rot13'),'ascii')
dec = base64.standard_b64decode(dec)
dec = xor(dec,19)
dec = bytes(codecs.encode(str(dec,'ascii'),'rot13'),'ascii')
dec = base64.standard_b64decode(dec)

print(type(dec))
print(dec)
~~~

Note: This could have been much more easily done through CyberChef rather than Python due to Python's finicky tendencies when working with bytes and bytesarray.

Flag: MIT{6a7efcac875b15950bdb19eaeea4aa0d}

## baby_jiangying

The program required for the user to input exactly 36 characters, of which it would then run through an encyption algorithm and check if the output matches the expected ciphertext. The encryption process involved iterating backwards through the string, iteratively calling a function on characters at string index at `i` and `i-1` and setting char at `i-1` to be the new value.

The character function has the following assembly code:

~~~asm
        001011e6 88 d0           MOV        AL,DL
        001011e8 fe c0           INC        AL
        001011ea c0 c0 05        ROL        AL,0x5
        001011ed 2c 2e           SUB        AL,46
        001011ef f6 d0           NOT        AL
        001011f1 34 73           XOR        AL,115
        001011f3 f6 d8           NEG        AL
        001011f5 c0 c8 09        ROR        AL,0x9
        001011f8 04 07           ADD        AL,0x7
        001011fa fe c8           DEC        AL
        001011fc 30 c8           XOR        AL,CL
        001011fe 88 c2           MOV        DL,AL
~~~

Note: AL stores char2 (`str[i-1]`) while CL stores char1 (`str[i]`).

This problem highlights the importance of looking at the assembly code rather than relying on just the decompiler's result. For comparison, this was the interpreted C code:

~~~c
char FUN_001011c9(char chr1,char chr2)

{
  byte bVar1;
  
  bVar1 = ~(((chr2 + 1U) * 32 | (byte)(chr2 + 1U) >> 3) - 46) ^ 115;
  return ((byte)-bVar1 >> 1 | bVar1 * -128) + 6 ^ chr1;
}
~~~

Couldn't believe the operations seemed more complicated in the decompiled version. 

To get the flag, we simply have to write a script which reverses the operation. Initially I got stumped in this step because I forgot that every reference to `str[i]` after the first loop will be using the ciphertext character located at `i` and not the initial value. I was recommended by Leo and Will on Discord to mod 256 the result after every operation since C ints are only 8 bits. For a more foolproof solution I will looking into using `ctypes` in Python (for future solves). Also, instead of reversing the enc process I can also try to guess the raw characters at `i-1` at each step. The solve script looks like this:


~~~py
inc = b'\x2b\xd1\x6b\x65\xea\x86\x3d\x86\x9b\x50\x6d\x71\x6c\x11\x3c\x40\x4c\x61\x7c\x30\x8b\x86\x8b\xa6\x8b\x86\xab\x86\xfb\x87\xaa\xd6\xeb\xa7\xcb\xc6\x7d'
inc = bytearray(inc)
inc.reverse()

out = list(b'}')
print(out)

rol = lambda val, r_bits, max_bits=8: \
    (val << r_bits%max_bits) & (2**max_bits-1) | \
    ((val & (2**max_bits-1)) >> (max_bits-(r_bits%max_bits)))

ror = lambda val, r_bits, max_bits=8: \
    ((val & (2**max_bits-1)) >> r_bits%max_bits) | \
    (val << (max_bits-(r_bits%max_bits)) & (2**max_bits-1))


for index, byte in enumerate(inc):
    if index == len(inc)-1:
        continue
    for i in range(256): # Guesser
        tmp = i + 1
        tmp = tmp % 256
        tmp = rol(tmp,0x5)
        tmp = tmp % 256
        tmp = tmp - 46
        tmp = tmp % 256
        tmp = ~tmp
        tmp = tmp % 256
        tmp = tmp ^ 115
        tmp = tmp % 256
        tmp = -1 * tmp
        tmp = tmp % 256
        tmp = ror(tmp,0x9)
        tmp = tmp % 256
        tmp = tmp + 0x7
        tmp = tmp % 256
        tmp = tmp - 1
        tmp = tmp % 256
        tmp = tmp ^ inc[index+1]
        tmp = tmp % 256
        if tmp == byte:    
            print(tmp)
            out.append(i)
            break
out.reverse()
print(bytes(out))
~~~

Flag: MIT{699c8a3ceb54bc09ddbbdbbe5b5a06d9}

## substandard_implementation

This was challenge that took me nearly 3 hours to solve, not because it was hard conceptually, but mainly because I had a tough time understanding and working with C types in Python. The binary took an `ulong` (unsigned 32 bit integers) array, and for each number, sent it to a function that computes the "encrypted" result.

The encryption algorithm is a simple recursive function which where `f(n) = f(n-1)*5 + f(n-2)*2 + f(n-1)` with the first three cases returning "M", "I", and "T". The reason why the computation takes so long in the original program is because it requires a lot of recursive calls, and without meimoization you would be doing a lot of extraneous computations.

My solve script ended looking like this:

~~~py

from functools import lru_cache
import ctypes
from Crypto.Util.number import bytes_to_long

input = b'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x2d\x00\x00\x00\xf4\x00\x00\x00\x8b\x01\x00\x00\x6a\x02\x00\x00\xb4\x02\x00\x00\x06\x03\x00\x00\x1f\x04\x00\x00\x40\x04\x00\x00\xce\x05\x00\x00\x00\x06\x00\x00\x3d\x06\x00\x00\x61\x06\x00\x00\xcb\x06\x00\x00\x21\x08\x00\x00\x37\x08\x00\x00\x80\x09\x00\x00\x1b\x0b\x00\x00\x2a\x0b\x00\x00\xdb\x0c\x00\x00\xcb\x0d\x00\x00\xaa\x0e\x00\x00\x4e\x10\x00\x00\x38\x11\x00\x00\xc4\x11\x00\x00\x1b\x12\x00\x00\xf8\x12\x00\x00\x77\x14\x00\x00\x9f\x15\x00\x00\x78\x16\x00\x00\xbd\x17\x00\x00\x1b\x19\x00\x00\xe3\x19\x00\x00\xce\x1a\x00\x00\x89\x1b\x00\x00'
print(len(input))

split = lambda str : [int.from_bytes(str[i:i+4],"little") for i in range(0, len(str), 4)] # Uses trick from : https://stackoverflow.com/questions/1887506/convert-python-byte-to-unsigned-8-bit-integer

parsed = split(input)

print(len(parsed))
print(parsed)

@lru_cache(None)
def magic(val):
    if val == 0:
        return 0x4d
    elif val == 1:
        return 0x49
    elif val == 2:
        return 0x54    
    return ctypes.c_ulonglong(magic(val-1)*5 + magic(val-2)*2 + magic(val-3)).value

out = []
for i in range(0x25):
    res = magic(parsed[i])
    print(res)
    out.append(res%256)

print(bytes(out))
~~~

Some things of note:

* Since the array is of unsigned long, not normal integers, they are 32 bits. Initially I made the mistake of blindly following a StackOverflow answer for converting bytes to integers which simply just takes the int value of the last byte in the split string. For numbers less than 256 that would have been fine. However, the proper method involves doing `int.from_bytes(num,"little")` for little-endian encoding.

* In the Ghidra decompiling result, Ghidra actually missed the integer paramter passed into the function. This was pointed out from a help question on the BinExp class Discord chat. However, I made the mistake of interpreting the asm as passing in the int * for the array, rather than the values itself, which caused an hour of confusion. At some point, I even accidentally renamed the argument register `RDI` as `int_array`, which made me go down a rabbit hole of being confused over why `MOV int_array, EAX` was an instruction before `call func1`. In the future, I will definitely be more careful about renaming variables and changing function types.

* When coding the script, I would sometimes copy over snippets I wrote but forget to change some keywords for the case they were supposed to represent. As a result, I would go 20 minutes trying to fix later parts of the code without realizing my recursive case was wrong.

Since the results of the magic function can be very larger (larger than 32 bits), it was necessary to do the ctypes conversion as suggested by Will. At the end I then take the last byte in each solution, which can be either with `% 256` or `* 0xff`. For the optimization step of the problem, I used the lru_cache option from `functools` to memoize my results. The final calculations ran very quickly (less than a second)


*Aside*: Also, at some point I considered coding this directly in C. Given that the highest input value to the function is `7049`, it's entirely possible to do this in C. I think with future problem I might attempt that instead so I don't have to worry about these pesky typing issues.

    

